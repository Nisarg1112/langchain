{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b69e747b-4e79-4caf-8f8b-c6e70275a31d",
   "metadata": {},
   "source": [
    "# Event Streaming\n",
    "\n",
    "--- IGNORE -- \n",
    "\n",
    "In this notebook, we'll see how to combine agents with callbacks to achieve **token by token streaming** from the underlying tools! We'll only\n",
    "stream the tokens from the underlying tools and **nothing else**! Feel free to adapt this to your application needs.\n",
    "\n",
    "Our agent will use the OpenAI tools API for tool invocation, and we'll provide the agent with two tools:\n",
    "\n",
    "1. `where_cat_is_hiding`: A tool that uses an LLM to tell us where the cat is hiding\n",
    "2. `tell_me_a_joke_about`: A tool that can use an LLM to tell a joke about the given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3cb97a-5af6-491f-9a82-a6ee3eaf2dd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING, Any, Dict, List, Optional, Sequence, TypeVar, Union\n",
    "from uuid import UUID\n",
    "\n",
    "from langchain import agents, hub\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools import tool\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.callbacks import Callbacks\n",
    "from langchain_core.callbacks.base import AsyncCallbackHandler\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.outputs import ChatGenerationChunk, GenerationChunk, LLMResult\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d828cccd-889f-4c15-a9a9-58af9dfac869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks.manager import CallbackManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b0fafa-ce3b-489b-bf1d-d37b87f4819e",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "\n",
    "**Attention** For older versions of langchain, we must set `streaming=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3c3761-a1cd-4118-8559-ea4d8857d394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e1a3b-2983-42d9-ac12-4a0f32cd4a24",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "We define two tools that rely on a chat model to generate output!\n",
    "\n",
    "Please note a few different things:\n",
    "\n",
    "1. We invoke the model using .stream() to force the output to stream (unfortunately for older langchain versions you should still set `streaming=True` on the model)\n",
    "2. We attach tags to the model so that we can filter on said tags in our callback handler\n",
    "3. The tools accept callbacks and propagate them to the model as a runtime argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c767f760-fe52-47e5-9c2a-622f03507aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "async def where_cat_is_hiding(callbacks: Callbacks) -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Where is the cat hiding right now?\"\"\"\n",
    "    chunks = [\n",
    "        chunk\n",
    "        async for chunk in model.astream(\n",
    "            \"Give one up to three word answer about where the cat might be hiding in the house right now.\",\n",
    "            {\n",
    "                \"tags\": [\"tool_llm\"],\n",
    "                \"callbacks\": callbacks,\n",
    "            },  # <--- Propagate callbacks and assign a tag to this model\n",
    "        )\n",
    "    ]\n",
    "    return \"\".join(chunk.content for chunk in chunks)\n",
    "\n",
    "\n",
    "@tool\n",
    "async def tell_me_a_joke_about(\n",
    "    topic: str, callbacks: Callbacks\n",
    ") -> str:  # <--- Accept callbacks\n",
    "    \"\"\"Tell a joke about a given topic.\"\"\"\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are Cat Agent 007. You are funny and know many jokes.\"),\n",
    "            (\"human\", \"Tell me a long joke about {topic}\"),\n",
    "        ]\n",
    "    )\n",
    "    chain = template | model.with_config({\"tags\": [\"tool_llm\"]})\n",
    "    chunks = [\n",
    "        chunk\n",
    "        async for chunk in chain.astream({\"topic\": topic}, {\"callbacks\": callbacks})\n",
    "    ]\n",
    "    return \"\".join(chunk.content for chunk in chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba476f8-29da-4c2c-9134-186871caf7ae",
   "metadata": {},
   "source": [
    "## Initialize the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0bab4488-bf4c-461f-b41e-5e60310fe0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "print(prompt.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1762f4e1-402a-4bfb-af26-eb5b7b8f56bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [tell_me_a_joke_about, where_cat_is_hiding]\n",
    "agent = agents.create_openai_tools_agent(\n",
    "    model.with_config({\"tags\": [\"agent\"]}), tools, prompt\n",
    ")\n",
    "executor = agents.AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5d94bd8-4a55-4527-b21a-4245a38c7c26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "Starting tool: where_cat_is_hiding with inputs: {}\n",
      "Under the bed.\n",
      "Ended tool: where_cat_is_hiding\n",
      "--\n",
      "--\n",
      "Starting tool: tell_me_a_joke_about with inputs: {'topic': 'under the bed'}\n",
      "Sure, here's a long joke about what's hiding under the bed:\n",
      "\n",
      "Once upon a time, there was a mischievous little boy named Timmy. Timmy had always been afraid of what might be lurking under his bed at night. Every evening, he would tiptoe into his room, turn off the lights, and then make a daring leap onto his bed, ensuring that nothing could grab his ankles.\n",
      "\n",
      "One night, Timmy's parents decided to play a prank on him. They hid a remote-controlled toy monster under his bed, complete with glowing eyes and a growling sound effect. As Timmy settled into bed, his parents quietly snuck into his room, ready to give him the scare of a lifetime.\n",
      "\n",
      "Just as Timmy was about to drift off to sleep, he heard a faint growl coming from under his bed. His eyes widened with fear, and his heart started racing. He mustered up the courage to peek under the bed, and to his surprise, he saw a pair of glowing eyes staring back at him.\n",
      "\n",
      "Terrified, Timmy jumped out of bed and ran to his parents, screaming, \"There's a monster under my bed! Help!\"\n",
      "\n",
      "His parents, trying to stifle their laughter, rushed into his room. They pretended to be just as scared as Timmy, and together, they bravely approached the bed. Timmy's dad grabbed a broomstick, ready to defend his family against the imaginary monster.\n",
      "\n",
      "As they got closer, the \"monster\" under the bed started to move. Timmy's mom, unable to contain her laughter any longer, pressed a button on the remote control, causing the toy monster to scurry out from under the bed. Timmy's fear quickly turned into confusion, and then into laughter as he realized it was all just a prank.\n",
      "\n",
      "From that day forward, Timmy learned that sometimes the things we fear the most are just figments of our imagination. And as for what's hiding under his bed? Well, it's just dust bunnies and the occasional missing sock. Nothing to be afraid of!\n",
      "\n",
      "So remember, my friend, the next time you're scared of what might be lurking under your bed, just grab a broomstick and face your fears. And if all else fails, just remember that laughter is the best monster repellent!\n",
      "Ended tool: tell_me_a_joke_about\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "async for event in executor.astream_events(\n",
    "    {\"input\": \"where is the cat hiding? Tell me a joke about that location?\"},\n",
    "    include_tags=[\"tool_llm\"],\n",
    "    include_types=[\"tool\"],\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_llm_stream\":\n",
    "        print(event[\"data\"][\"chunk\"].content, end=\"\")\n",
    "    if kind == \"on_llm_end\":\n",
    "        print()\n",
    "    if kind == \"on_tool_start\":\n",
    "        print(\"--\")\n",
    "        print(\n",
    "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input', {})}\"\n",
    "        )  # Fix bug with empty events should be empty dict\n",
    "    if kind == \"on_tool_end\":\n",
    "        print(f\"Ended tool: {event['name']}\")\n",
    "        print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906af691-9f2b-4296-894c-2c478bddbd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
